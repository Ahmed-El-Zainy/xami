# services/gemini_service.py
import asyncio
import time
from typing import List, Dict, Any, Optional
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import json
import os 
import sys 


SCR_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.dirname(os.path.dirname(SCR_DIR)))

from src.config.config_settings import settings
from src.config.logging_config import get_logger, log_execution_time, CustomLoggerTracker
from src.models.schemas import SearchResult, RAGResponse
from src.utilities.arabic_utils import arabic_processor


try:
    # from logger.custom_logger import CustomLoggerTracker
    custom = CustomLoggerTracker()
    logger = custom.get_logger("gemini_serivce")
    logger.info("Custom Logger Start Working.....")

except ImportError:
    import logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logger = logging.getLogger("gemini_service")
    logger.info("Using standard logger - custom logger not available")


class GeminiService:
    def __init__(self):
        self.logger = get_logger(__name__)
        self.model = None
        self.generation_config = None
        self.safety_settings = None
        self._initialized = False
        
    async def initialize(self):
        """Initialize Gemini API"""
        if self._initialized:
            return
            
        try:
            if not settings.GEMINI_API_KEY:
                raise ValueError("GEMINI_API_KEY not provided in settings")
            
            self.logger.info(f"Initializing Gemini API with model: {settings.GEMINI_MODEL}")
            
            # Configure the API
            genai.configure(api_key=settings.GEMINI_API_KEY)
            
            # Initialize the model
            self.model = genai.GenerativeModel(
                model_name=settings.GEMINI_MODEL,
                generation_config=self._get_generation_config(),
                safety_settings=self._get_safety_settings()
            )
            
            # Test the model
            test_response = await self._generate_text("Ù…Ø±Ø­Ø¨Ø§")
            self.logger.info("Gemini API initialized successfully")
            self._initialized = True
            
        except Exception as e:
            self.logger.error(f"Failed to initialize Gemini API: {str(e)}")
            raise
    
    def _get_generation_config(self):
        """Get generation configuration for Gemini"""
        return genai.types.GenerationConfig(
            candidate_count=1,
            temperature=0.7,
            top_p=0.8,
            top_k=40,
            max_output_tokens=2048,
        )
    
    def _get_safety_settings(self):
        """Get safety settings for Gemini"""
        return [
            {
                "category": HarmCategory.HARM_CATEGORY_HARASSMENT,
                "threshold": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
            },
            {
                "category": HarmCategory.HARM_CATEGORY_HATE_SPEECH,
                "threshold": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
            },
            {
                "category": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
                "threshold": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
            },
            {
                "category": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
                "threshold": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE
            },
        ]
    
    @log_execution_time
    async def generate_rag_response(
        self, 
        query: str, 
        search_results: List[SearchResult],
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> RAGResponse:
        """Generate RAG response using Gemini"""
        if not self._initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            self.logger.info(f"Generating RAG response for query: {query[:50]}...")
            
            # Build the prompt
            prompt = await self._build_rag_prompt(query, search_results, conversation_history)
            
            # Generate response
            response_text = await self._generate_text(prompt)
            
            # Calculate confidence score
            confidence_score = await self._calculate_confidence_score(
                query, response_text, search_results
            )
            
            processing_time = time.time() - start_time
            
            # Create RAG response
            rag_response = RAGResponse(
                query=query,
                answer=response_text,
                sources=search_results,
                processing_time=processing_time,
                confidence_score=confidence_score
            )
            
            self.logger.info(f"RAG response generated successfully in {processing_time:.2f}s")
            return rag_response
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"Error generating RAG response: {str(e)}")
            
            # Return error response
            return RAGResponse(
                query=query,
                answer=f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø¤Ø§Ù„Ùƒ: {str(e)}",
                sources=search_results,
                processing_time=processing_time,
                confidence_score=0.0
            )
    
    async def _build_rag_prompt(
        self, 
        query: str, 
        search_results: List[SearchResult],
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """Build the RAG prompt for Gemini"""
        
        # Detect query language
        query_language = arabic_processor.detect_language(query)
        
        # Build context from search results
        context_parts = []
        for i, result in enumerate(search_results[:5], 1):  # Use top 5 results
            context_parts.append(f"[Ù…ØµØ¯Ø± {i}]\n{result.text}\n")
        
        context = "\n".join(context_parts)
        
        # Build conversation history
        history_text = ""
        if conversation_history:
            history_parts = []
            for turn in conversation_history[-3:]:  # Last 3 turns
                history_parts.append(f"Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {turn.get('user', '')}")
                history_parts.append(f"Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯: {turn.get('assistant', '')}")
            history_text = "\n".join(history_parts)
        
        # Choose prompt based on language
        if query_language == "ar" or query_language == "mixed":
            prompt = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø«Ø§Ù†ÙˆÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠ. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·Ù„Ø§Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù….

{'## Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:' + chr(10) + history_text + chr(10) if history_text else ''}

## Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ:
{context}

## Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨:
{query}

## ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
1. Ø§Ø¬Ø¨ Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¯Ù‚Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
2. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ Ø§Ù„Ù…Ù‚Ø¯Ù… Ø£Ø¹Ù„Ø§Ù‡ ÙÙ‚Ø·
3. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØŒ Ø§Ø°ÙƒØ± Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­
4. Ù‚Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†
5. Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚Ø§Ù‹ ÙˆØ§Ø¶Ø­Ø§Ù‹ Ù…Ø¹ Ù†Ù‚Ø§Ø· Ø£Ùˆ ØªØ±Ù‚ÙŠÙ… Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
6. ØªØ£ÙƒØ¯ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ù„Ù…ÙŠØ© ÙˆØ§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©

## Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"""
        else:
            prompt = f"""You are an intelligent assistant specialized in Arabic secondary education. Your task is to answer student questions based on the provided educational content.

{'## Previous Conversation Context:' + chr(10) + history_text + chr(10) if history_text else ''}

## Reference Educational Content:
{context}

## Student Question:
{query}

## Answer Instructions:
1. Answer clearly and accurately in Arabic
2. Use only the reference content provided above
3. If you cannot find the answer in the reference content, state this clearly
4. Provide practical examples when possible
5. Use clear formatting with bullet points or numbering when needed
6. Ensure accuracy of scientific and mathematical information

## Answer:"""
        
        return prompt
    
    async def _generate_text(self, prompt: str) -> str:
        """Generate text using Gemini"""
        try:
            # Create async wrapper for Gemini API
            loop = asyncio.get_event_loop()
            
            response = await loop.run_in_executor(
                None, 
                lambda: self.model.generate_content(prompt)
            )
            
            if response.candidates and response.candidates[0].content:
                return response.candidates[0].content.parts[0].text
            else:
                return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ø³Ø¤Ø§Ù„Ùƒ."
                
        except Exception as e:
            self.logger.error(f"Error generating text with Gemini: {str(e)}")
            return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: {str(e)}"
    
    async def _calculate_confidence_score(
        self, 
        query: str, 
        response: str, 
        search_results: List[SearchResult]
    ) -> float:
        """Calculate confidence score for the response"""
        try:
            confidence_factors = []
            
            # 1. Source quality (average of search result scores)
            if search_results:
                avg_source_score = sum(r.score for r in search_results) / len(search_results)
                confidence_factors.append(avg_source_score)
            
            # 2. Response length appropriateness
            response_length = len(response.split())
            if 10 <= response_length <= 200:  # Reasonable length
                length_score = 1.0
            elif response_length < 10:
                length_score = 0.3  # Too short
            else:
                length_score = max(0.5, 1.0 - (response_length - 200) / 300)  # Too long
            confidence_factors.append(length_score)
            
            # 3. Language consistency
            query_lang = arabic_processor.detect_language(query)
            response_lang = arabic_processor.detect_language(response)
            lang_consistency = 1.0 if query_lang == response_lang else 0.7
            confidence_factors.append(lang_consistency)
            
            # 4. Error indicators
            error_indicators = ["Ø¹Ø°Ø±Ø§Ù‹", "Ø®Ø·Ø£", "Ù„Ù… Ø£ØªÙ…ÙƒÙ†", "ØºÙŠØ± Ù…ØªØ£ÙƒØ¯"]
            has_error = any(indicator in response for indicator in error_indicators)
            error_score = 0.3 if has_error else 1.0
            confidence_factors.append(error_score)
            
            # Calculate weighted average
            weights = [0.4, 0.2, 0.2, 0.2]  # Source quality is most important
            confidence_score = sum(f * w for f, w in zip(confidence_factors, weights))
            
            return min(max(confidence_score, 0.0), 1.0)  # Clamp to [0, 1]
            
        except Exception as e:
            self.logger.error(f"Error calculating confidence score: {str(e)}")
            return 0.5  # Default moderate confidence
    
    async def summarize_text(self, text: str, max_length: int = 200) -> str:
        """Summarize text using Gemini"""
        if not self._initialized:
            await self.initialize()
        
        try:
            language = arabic_processor.detect_language(text)
            
            if language == "ar" or language == "mixed":
                prompt = f"""Ù„Ø®Øµ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ {max_length} ÙƒÙ„Ù…Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰:

{text}

Ø§Ù„Ù…Ù„Ø®Øµ:"""
            else:
                prompt = f"""Summarize the following text in maximum {max_length} words in Arabic:

{text}

Summary:"""
            
            summary = await self._generate_text(prompt)
            return summary
            
        except Exception as e:
            self.logger.error(f"Error summarizing text: {str(e)}")
            return text[:max_length] + "..." if len(text) > max_length else text
    
    async def generate_questions(self, text: str, num_questions: int = 3) -> List[str]:
        """Generate questions based on text content"""
        if not self._initialized:
            await self.initialize()
        
        try:
            prompt = f"""Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„ØªØ§Ù„ÙŠØŒ Ø£Ù†Ø´Ø¦ {num_questions} Ø£Ø³Ø¦Ù„Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù…ÙÙŠØ¯Ø©:

{text}

Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:"""
            
            response = await self._generate_text(prompt)
            
            # Parse questions from response
            questions = []
            for line in response.split('\n'):
                line = line.strip()
                if line and (line.startswith('- ') or line.startswith('â€¢ ') or 
                           any(line.startswith(f'{i}.') for i in range(1, 11))):
                    # Clean the question
                    question = line.lstrip('- â€¢ 0123456789. ').strip()
                    if question:
                        questions.append(question)
            
            return questions[:num_questions]
            
        except Exception as e:
            self.logger.error(f"Error generating questions: {str(e)}")
            return []
    
    async def explain_concept(self, concept: str, context: str = "") -> str:
        """Explain a concept in simple terms"""
        if not self._initialized:
            await self.initialize()
        
        try:
            prompt = f"""Ø§Ø´Ø±Ø­ Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø© Ù„Ø·Ø§Ù„Ø¨ ÙÙŠ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©:

Ø§Ù„Ù…ÙÙ‡ÙˆÙ…: {concept}

{f'Ø§Ù„Ø³ÙŠØ§Ù‚: {context}' if context else ''}

Ø§Ù„Ø´Ø±Ø­:"""
            
            explanation = await self._generate_text(prompt)
            return explanation
            
        except Exception as e:
            self.logger.error(f"Error explaining concept: {str(e)}")
            return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø´Ø±Ø­ Ø§Ù„Ù…ÙÙ‡ÙˆÙ…: {concept}"
    
    async def translate_text(self, text: str, target_language: str = "ar") -> str:
        """Translate text to target language"""
        if not self._initialized:
            await self.initialize()
        
        try:
            if target_language == "ar":
                prompt = f"""ØªØ±Ø¬Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø¯Ù‚Ø© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø¹Ù„Ù…ÙŠ:

{text}

Ø§Ù„ØªØ±Ø¬Ù…Ø©:"""
            else:
                prompt = f"""Translate the following Arabic text to {target_language} accurately while maintaining scientific meaning:

{text}

Translation:"""
            
            translation = await self._generate_text(prompt)
            return translation
            
        except Exception as e:
            self.logger.error(f"Error translating text: {str(e)}")
            return text
    
    async def evaluate_answer(self, question: str, student_answer: str, correct_answer: str) -> Dict[str, Any]:
        """Evaluate student answer against correct answer"""
        if not self._initialized:
            await self.initialize()
        
        try:
            prompt = f"""Ù‚Ù… Ø¨ØªÙ‚ÙŠÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© ÙˆØ£Ø¹Ø· ØªÙ‚ÙŠÙŠÙ…Ø§Ù‹ Ù…ÙØµÙ„Ø§Ù‹:

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}

Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø·Ø§Ù„Ø¨: {student_answer}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©: {correct_answer}

ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙÙŠ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„ØªØ§Ù„ÙŠ:
- Ø§Ù„Ø¯Ø±Ø¬Ø©: (Ù…Ù† 0 Ø¥Ù„Ù‰ 10)
- Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„ØµØ­ÙŠØ­Ø©:
- Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©:
- Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†:

Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:"""
            
            evaluation = await self._generate_text(prompt)
            
            # Try to parse score from response
            score = 5  # default score
            lines = evaluation.split('\n')
            for line in lines:
                if 'Ø§Ù„Ø¯Ø±Ø¬Ø©' in line or 'Score' in line:
                    # Try to extract number
                    import re
                    numbers = re.findall(r'\d+', line)
                    if numbers:
                        score = min(10, max(0, int(numbers[0])))
                        break
            
            return {
                "score": score,
                "max_score": 10,
                "evaluation": evaluation,
                "percentage": (score / 10) * 100
            }
            
        except Exception as e:
            self.logger.error(f"Error evaluating answer: {str(e)}")
            return {
                "score": 0,
                "max_score": 10,
                "evaluation": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {str(e)}",
                "percentage": 0
            }
    
    async def health_check(self) -> bool:
        """Check if Gemini API is working"""
        try:
            if not self._initialized:
                await self.initialize()
            
            test_response = await self._generate_text("Ù…Ø±Ø­Ø¨Ø§")
            return len(test_response) > 0
            
        except Exception as e:
            self.logger.error(f"Gemini health check failed: {str(e)}")
            return False
    
    async def get_service_info(self) -> Dict[str, Any]:
        """Get service information and status"""
        try:
            is_healthy = await self.health_check()
            
            return {
                "service": "Gemini Service",
                "model": settings.GEMINI_MODEL if hasattr(settings, 'GEMINI_MODEL') else "Unknown",
                "initialized": self._initialized,
                "healthy": is_healthy,
                "capabilities": [
                    "RAG Response Generation",
                    "Text Summarization", 
                    "Question Generation",
                    "Concept Explanation",
                    "Text Translation",
                    "Answer Evaluation"
                ]
            }
        except Exception as e:
            return {
                "service": "Gemini Service",
                "error": str(e),
                "healthy": False
            }


# Global Gemini service instance
gemini_service = GeminiService()


# Test Sample and Usage Examples
async def test_gemini_service():
    """Comprehensive test suite for Gemini Service"""
    print("=" * 60)
    print("ğŸš€ Testing Gemini Service")
    print("=" * 60)
    
    try:
        # Initialize service
        print("1. Initializing Gemini Service...")
        await gemini_service.initialize()
        print("   âœ… Service initialized successfully")
        
        # Test health check
        print("\n2. Testing health check...")
        health = await gemini_service.health_check()
        print(f"   âœ… Health check: {'Passed' if health else 'Failed'}")
        
        # Test service info
        print("\n3. Getting service information...")
        info = await gemini_service.get_service_info()
        print(f"   âœ… Service Info:")
        for key, value in info.items():
            print(f"      {key}: {value}")
        
        # Create sample search results
        sample_search_results = [
            SearchResult(
                text="Ø§Ù„Ø®Ù„ÙŠØ© Ù‡ÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø­ÙŠØ§Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ø­ÙŠØ©. ØªØ­ØªÙˆÙŠ Ø§Ù„Ø®Ù„ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„ØªÙŠ ØªØ­Ù…Ù„ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ© DNA.",
                score=0.9,
                source="ÙƒØªØ§Ø¨ Ø§Ù„Ø£Ø­ÙŠØ§Ø¡ - Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠ",
                metadata={"chapter": "Ø§Ù„Ø®Ù„ÙŠØ©", "page": 15}
            ),
            SearchResult(
                text="ØªÙ†Ù‚Ø³Ù… Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø¥Ù„Ù‰ Ù†ÙˆØ¹ÙŠÙ† Ø±Ø¦ÙŠØ³ÙŠÙŠÙ†: Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø¨Ø¯Ø§Ø¦ÙŠØ© Ø§Ù„Ù†ÙˆØ§Ø© ÙˆØ§Ù„Ø®Ù„Ø§ÙŠØ§ Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø§Ù„Ù†ÙˆØ§Ø©. Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø§Ù„Ù†ÙˆØ§Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ÙˆØ§Ø© Ù…Ø­Ø§Ø·Ø© Ø¨ØºØ´Ø§Ø¡.",
                score=0.85,
                source="Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø­ÙŠØ§Ø¡",
                metadata={"topic": "Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø®Ù„Ø§ÙŠØ§"}
            )
        ]
        
        # Test RAG response generation
        print("\n4. Testing RAG response generation...")
        query = "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø®Ù„ÙŠØ© ÙˆÙ…Ø§ Ø£Ù†ÙˆØ§Ø¹Ù‡Ø§ØŸ"
        rag_response = await gemini_service.generate_rag_response(query, sample_search_results)
        print(f"   âœ… RAG Response generated:")
        print(f"      Query: {rag_response.query}")
        print(f"      Answer: {rag_response.answer[:100]}...")
        print(f"      Confidence: {rag_response.confidence_score:.2f}")
        print(f"      Processing Time: {rag_response.processing_time:.2f}s")
        
        # Test with conversation history
        print("\n5. Testing RAG with conversation history...")
        conversation_history = [
            {"user": "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø®Ù„ÙŠØ©ØŸ", "assistant": "Ø§Ù„Ø®Ù„ÙŠØ© Ù‡ÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø­ÙŠØ§Ø©"},
            {"user": "Ø£Ø±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯", "assistant": "ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø´Ø±Ø­ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø®Ù„Ø§ÙŠØ§"}
        ]
        rag_response_with_history = await gemini_service.generate_rag_response(
            "Ø§Ø´Ø±Ø­ Ù„ÙŠ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø®Ù„Ø§ÙŠØ§", 
            sample_search_results, 
            conversation_history
        )
        print(f"   âœ… RAG with history: {rag_response_with_history.answer[:100]}...")
        
        # Test text summarization
        print("\n6. Testing text summarization...")
        long_text = """Ø§Ù„Ø®Ù„ÙŠØ© Ù‡ÙŠ Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø­ÙŠØ§Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø§Ù„Ø­ÙŠØ©. ØªØ­ØªÙˆÙŠ Ø§Ù„Ø®Ù„ÙŠØ© Ø¹Ù„Ù‰ Ù…ÙƒÙˆÙ†Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ù…Ø«Ù„ Ø§Ù„Ù†ÙˆØ§Ø© ÙˆØ§Ù„Ø³ÙŠØªÙˆØ¨Ù„Ø§Ø²Ù… ÙˆØ§Ù„ØºØ´Ø§Ø¡ Ø§Ù„Ø®Ù„ÙˆÙŠ. Ø§Ù„Ù†ÙˆØ§Ø© ØªØ­Ù…Ù„ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ© DNA Ø§Ù„ØªÙŠ ØªØ­Ø¯Ø¯ ØµÙØ§Øª Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ø­ÙŠ. Ø§Ù„Ø³ÙŠØªÙˆØ¨Ù„Ø§Ø²Ù… Ù‡Ùˆ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù‡Ù„Ø§Ù…ÙŠØ© Ø§Ù„ØªÙŠ ØªØ­ÙŠØ· Ø¨Ø§Ù„Ù†ÙˆØ§Ø© ÙˆØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¶ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù…Ø«Ù„ Ø§Ù„Ù…ÙŠØªÙˆÙƒÙˆÙ†Ø¯Ø±ÙŠØ§ ÙˆØ§Ù„Ø±ÙŠØ¨ÙˆØ³ÙˆÙ…Ø§Øª. Ø§Ù„ØºØ´Ø§Ø¡ Ø§Ù„Ø®Ù„ÙˆÙŠ ÙŠØ­ÙŠØ· Ø¨Ø§Ù„Ø®Ù„ÙŠØ© ÙˆÙŠØªØ­ÙƒÙ… ÙÙŠ Ø¯Ø®ÙˆÙ„ ÙˆØ®Ø±ÙˆØ¬ Ø§Ù„Ù…ÙˆØ§Ø¯."""
        summary = await gemini_service.summarize_text(long_text, max_length=50)
        print(f"   âœ… Summary: {summary}")
        
        # Test question generation
        print("\n7. Testing question generation...")
        educational_text = "Ø§Ù„Ù…ÙŠØªÙˆÙƒÙˆÙ†Ø¯Ø±ÙŠØ§ Ù‡ÙŠ Ø¹Ø¶ÙŠØ© Ø®Ù„ÙˆÙŠØ© ØªÙØ¹Ø±Ù Ø¨Ø£Ù†Ù‡Ø§ Ù…ØµÙ†Ø¹ Ø§Ù„Ø·Ø§Ù‚Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙŠØ©. ØªÙ‚ÙˆÙ… Ø§Ù„Ù…ÙŠØªÙˆÙƒÙˆÙ†Ø¯Ø±ÙŠØ§ Ø¨Ø¥Ù†ØªØ§Ø¬ ATP Ù…Ù† Ø®Ù„Ø§Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ†ÙØ³ Ø§Ù„Ø®Ù„ÙˆÙŠ."
        questions = await gemini_service.generate_questions(educational_text, num_questions=3)
        print(f"   âœ… Generated Questions:")
        for i, question in enumerate(questions, 1):
            print(f"      {i}. {question}")
        
        # Test concept explanation
        print("\n8. Testing concept explanation...")
        concept = "Ø§Ù„ØªÙ†ÙØ³ Ø§Ù„Ø®Ù„ÙˆÙŠ"
        context = "Ø¹Ù…Ù„ÙŠØ© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¬Ù„ÙˆÙƒÙˆØ² Ø¥Ù„Ù‰ Ø·Ø§Ù‚Ø© ÙÙŠ Ø§Ù„Ù…ÙŠØªÙˆÙƒÙˆÙ†Ø¯Ø±ÙŠØ§"
        explanation = await gemini_service.explain_concept(concept, context)
        print(f"   âœ… Concept Explanation: {explanation[:150]}...")
        
        # Test translation
        print("\n9. Testing translation...")
        english_text = "Photosynthesis is the process by which plants convert sunlight into energy."
        translation = await gemini_service.translate_text(english_text, "ar")
        print(f"   âœ… Translation: {translation}")
        
        # Test answer evaluation
        print("\n10. Testing answer evaluation...")
        question = "Ù…Ø§ Ù‡ÙŠ ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù…ÙŠØªÙˆÙƒÙˆÙ†Ø¯Ø±ÙŠØ§ØŸ"
        student_answer = "Ø§Ù„Ù…ÙŠØªÙˆÙƒÙˆÙ†Ø¯Ø±ÙŠØ§ ØªÙ†ØªØ¬ Ø§Ù„Ø·Ø§Ù‚Ø© Ù„Ù„Ø®Ù„ÙŠØ©"
        correct_answer = "Ø§Ù„Ù…ÙŠØªÙˆÙƒÙˆÙ†Ø¯Ø±ÙŠØ§ Ù‡ÙŠ Ø¹Ø¶ÙŠØ© Ø®Ù„ÙˆÙŠØ© Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø·Ø§Ù‚Ø© (ATP) Ù…Ù† Ø®Ù„Ø§Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ†ÙØ³ Ø§Ù„Ø®Ù„ÙˆÙŠ"
        evaluation = await gemini_service.evaluate_answer(question, student_answer, correct_answer)
        print(f"   âœ… Answer Evaluation:")
        print(f"      Score: {evaluation['score']}/{evaluation['max_score']}")
        print(f"      Percentage: {evaluation['percentage']}%")
        print(f"      Evaluation: {evaluation['evaluation'][:100]}...")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ All tests completed successfully!")
        print("=" * 60)
        
    except Exception as e:
        print(f"âŒ Test failed: {str(e)}")
        import traceback
        traceback.print_exc()


# Performance test
async def performance_test():
    """Test service performance with multiple concurrent requests"""
    print("\nğŸ”¥ Running Performance Test...")
    
    queries = [
        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø®Ù„ÙŠØ©ØŸ",
        "Ø§Ø´Ø±Ø­ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¶ÙˆØ¦ÙŠ",
        "Ù…Ø§ Ù‡ÙŠ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ù†Ø³Ø¬Ø©ØŸ",
        "ÙƒÙŠÙ ÙŠØªÙ… Ø§Ù„ØªÙ†ÙØ³ Ø§Ù„Ø®Ù„ÙˆÙŠØŸ",
        "Ù…Ø§ Ù‡ÙŠ ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø¯Ù…ØŸ"
    ]
    
    sample_results = [
        SearchResult(
            text="Ù†Øµ ØªØ¹Ù„ÙŠÙ…ÙŠ Ù…ØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ø³Ø¤Ø§Ù„",
            score=0.8,
            source="Ù…ØµØ¯Ø± ØªØ¹Ù„ÙŠÙ…ÙŠ",
            metadata={}
        )
    ]
    
    start_time = time.time()
    
    # Run concurrent requests
    tasks = [
        gemini_service.generate_rag_response(query, sample_results) 
        for query in queries
    ]
    
    responses = await asyncio.gather(*tasks, return_exceptions=True)
    
    total_time = time.time() - start_time
    
    successful = sum(1 for r in responses if isinstance(r, RAGResponse))
    failed = len(responses) - successful
    
    print(f"Performance Results:")
    print(f"  Total requests: {len(queries)}")
    print(f"  Successful: {successful}")
    print(f"  Failed: {failed}")
    print(f"  Total time: {total_time:.2f}s")
    print(f"  Average time per request: {total_time/len(queries):.2f}s")


if __name__ == "__main__":
    async def main():
        # Run comprehensive tests
        await test_gemini_service()
        
        # Run performance tests
        await performance_test()
    
    # Run the tests
    asyncio.run(main())